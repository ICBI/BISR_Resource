{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICBI/BISR_Tutorials/blob/main/scRNA_seq/SCRNAseq_Seurat_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ltdwXvN0dio"
      },
      "source": [
        "# Tutorial 2 - single cell RNA-seq (scRNA-seq) data analysis of mouse samples from 10X\n",
        "\n",
        "Authors: Krithika Bhuvaneshwar, Yuriy Gusev\n",
        "\n",
        "Affiliation: Innovation Center For Biomedical Informatics (ICBI), and Biomedical Informatics Shared Resource (BISR) at Georgetown University Medical Center (GUMC)\n",
        "\n",
        "***More about our research work:***\n",
        "* *ICBI: https://icbi.georgetown.edu*\n",
        "* *BISR: https://icbi.georgetown.edu/bisr/ and https://lombardi.georgetown.edu/research/sharedresources/bbsr/*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuA9crRB6shg"
      },
      "source": [
        "## General Steps in analysis\n",
        "Based on the workflow mentioned in the e-book \"Orchestrating Single-Cell Analysis with Bioconductor\"\n",
        "* Removal of low-quality cells\n",
        "* Normalization and log-transformation\n",
        "* Modeling of the mean-variance trend across genes\n",
        "* A principal components analysis on the highly variable genes\n",
        "* Clustering with graph-based methods\n",
        "* Dimensionality reductions (t-SNE/UMAP)\n",
        "* Marker detection for each cluster\n",
        "* Make custom cell selections and detect markers for this selection\n",
        "* Cell type annotation for each cluster across user selected reference datasets\n",
        "* Perform Integration or Batch correction using MNN correction.\n",
        "* Support Multi-modal analysis for Cite-seq data\n",
        "* Perform analysis on subsets (filter based on cell annotation)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps for anlaysis using Seurat\n",
        "\n",
        "* Setup the Seurat Object\n",
        "* Standard pre-processing workflow\n",
        "* Normalizing the data\n",
        "* Identification of highly variable features (feature selection)\n",
        "* Scaling the data\n",
        "* Perform linear dimensional reduction\n",
        "* Determine the ‘dimensionality’ of the dataset\n",
        "* Cluster the cells\n",
        "* Run non-linear dimensional reduction (UMAP/tSNE)\n",
        "* Finding differentially expressed features (cluster biomarkers)\n",
        "* Assigning cell type identity to clusters"
      ],
      "metadata": {
        "id": "nIbGX4ZOv2hD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KMphPwYFegF"
      },
      "source": [
        "##  Before we start\n",
        "\n",
        "### Change Run type to R\n",
        "If using google colab, change the colab runtype environment to R (default is python). Go to  Runtime -> Change runtime type -> In the \"Notebook settings\", change environment to \"R\"\n",
        "\n",
        "### Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Mount google drive\n",
        "install.packages(\"googledrive\") #only need to install occasionally install.packages(“httpuv”)\n",
        "library(\"googledrive\")"
      ],
      "metadata": {
        "id": "Jyel5v3Vpyzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#may update python version  #occasionally\n",
        "if (file.exists(\"/usr/local/lib/python3.7/dist-packages/google/colab/_ipython.py\")) {\n",
        "  install.packages(\"R.utils\")\n",
        "  library(\"R.utils\")\n",
        "  library(\"httr\")\n",
        "  my_check <- function() {return(TRUE)}\n",
        "  reassignInPackage(\"is_interactive\", pkgName = \"httr\", my_check)\n",
        "  options(rlang_interactive=TRUE)\n",
        "}"
      ],
      "metadata": {
        "id": "OhrcIeVXqFot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mc-l9NGER1z"
      },
      "source": [
        "## Example using Seurat workflow in R\n",
        "In this example, we will use the Seurat package (Link: https://satijalab.org/seurat/articles/get_started.html)\n",
        "\n",
        "Citation for this tutorial: https://learn.gencore.bio.nyu.edu/single-cell-rnaseq/loading-your-own-data-in-seurat-reanalyze-a-different-dataset/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Dataset\n",
        "* The data is available by following THIS link.\n",
        "* 1k Brain Cells from an E18 Mouse\n",
        "* Chromium Demonstration (v2 Chemistry) Dataset by Cell Ranger 2.1.0\n",
        "* Cells from a combined cortex, hippocampus and sub ventricular zone of an E18 mouse.\n",
        "* 931 cells detected\n",
        "* Sequenced on Illumina HiSeq2500 with approximately 56,000 reads per cell\n",
        "26bp read1 (16bp Chromium barcode and 10bp UMI), 98bp read2 (transcript), and 8bp * I7 sample barcode\n",
        "* Analysis run with —cells=2000.\n",
        "\n",
        "### Note\n",
        "Please download the input data files from either location listed above, and load it to your google drive folder `sample_data` that you can see on the left panel. Full path is `/content/sample_data/`"
      ],
      "metadata": {
        "id": "9PdotLwlc7xG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-q4boZ4EYGz"
      },
      "source": [
        "## Installation packages and dependencies\n",
        "Takes several minutes to complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQyxLw9vEa-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6c4887-991f-4f10-e8c4-6a69b6a78c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘bitops’, ‘gtools’, ‘caTools’, ‘plyr’, ‘tensor’, ‘BH’, ‘sitmo’, ‘globals’, ‘listenv’, ‘parallelly’, ‘zoo’, ‘htmlwidgets’, ‘lazyeval’, ‘crosstalk’, ‘promises’, ‘RcppTOML’, ‘here’, ‘gplots’, ‘reshape2’, ‘gridExtra’, ‘RcppArmadillo’, ‘sp’, ‘httpuv’, ‘xtable’, ‘sourcetools’, ‘later’, ‘spatstat.data’, ‘spatstat.random’, ‘spatstat.utils’, ‘spatstat.sparse’, ‘goftest’, ‘abind’, ‘deldir’, ‘polyclip’, ‘FNN’, ‘dqrng’, ‘cowplot’, ‘fitdistrplus’, ‘future’, ‘future.apply’, ‘ggrepel’, ‘ggridges’, ‘ica’, ‘igraph’, ‘irlba’, ‘leiden’, ‘lmtest’, ‘matrixStats’, ‘miniUI’, ‘patchwork’, ‘pbapply’, ‘plotly’, ‘png’, ‘progressr’, ‘RANN’, ‘Rcpp’, ‘RcppAnnoy’, ‘reticulate’, ‘ROCR’, ‘Rtsne’, ‘scattermore’, ‘sctransform’, ‘SeuratObject’, ‘shiny’, ‘spatstat.explore’, ‘spatstat.geom’, ‘uwot’, ‘RcppEigen’, ‘RcppProgress’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"Seurat\")\n",
        "\n",
        "library(dplyr)\n",
        "library(Seurat)\n",
        "library(patchwork)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load input data\n",
        "\n",
        "We start by reading in the data. The `Read10X()` function reads in the output of the cellranger pipeline from 10X, returning a **unique molecular identified (UMI) count matrix.**\n",
        "The values in this matrix represent the number of molecules for each feature (i.e. gene; row) that are detected in each cell (column).\n",
        "\n",
        "We next use the count matrix to create a **Seurat object.** The object serves as a container that contains both data (like the count matrix) and analysis (like PCA, or clustering results) for a single-cell dataset.  For example, the count matrix is stored in pbmc[[\"RNA\"]]@counts.\n",
        "\n",
        "* The `cellranger` pipeline from 10X takes the raw fastq files and processes it. For this tutorial, this step is already completed\n",
        "* The `Read10X()` function reads in the output of the `cellranger` pipeline from 10X and returns a unique molecular identified (UMI) count matrix\n",
        "* The values in this matrix represent the number of molecules for each feature (i.e. gene; row) that are detected in each cell (column).\n",
        "\n",
        "## Important\n",
        "Load input data to your google drive location. For this example, the path to input folder is `/content/sample_data/`. Can change path as needed in the URL below\n"
      ],
      "metadata": {
        "id": "T8Cq7-BwvODa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PBMC data directory\n",
        "pbmc.data <- Read10X(data.dir = \"/content/sample_data/raw_gene_bc_matrices/mm10/\")"
      ],
      "metadata": {
        "id": "49htNuT-vWff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about this object"
      ],
      "metadata": {
        "id": "fd55RZAAsyf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Learn more about this object\n",
        "print(\"Dimensions\")\n",
        "dim(pbmc.data)\n",
        "\n",
        "#The object serves as a container that contains both data and meta data\n",
        "print(\"Structure\")\n",
        "str(pbmc.data)"
      ],
      "metadata": {
        "id": "Eob9bYtRsx1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Seurat object and initial pre-filtering\n",
        "Initialize the Seurat object with the raw (non-normalized count data)\n",
        "\n",
        "Initial prefiltering is done at the gene and cell level by excluding any genes that are not expressed in at least 3 cells, and excluding any genes that do not have a minimum of 200 expressed genes in total.\n",
        "\n",
        "Use the count matrix to create a Seurat object. The object serves as a container that contains both data (like the count matrix) and analysis (like PCA, or clustering results) for a single-cell dataset. For example, the count matrix is stored in pbmc[[\"RNA\"]]@counts.\n",
        "\n",
        "Note- Depending on your experiment and data, you might want to experiment with these cutoffs. For example, you might want to adjust the minimum number of detected genes to a higher threshold if you have deep coverage, or not impose it completely in case you have a very low number of reads for your cells.\n",
        "[Reference: https://learn.gencore.bio.nyu.edu/single-cell-rnaseq/seurat-part-1-loading-the-data/]"
      ],
      "metadata": {
        "id": "mVJ4Gf-Hwxoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Seurat object with the raw (non-normalized data).\n",
        "pbmc <- CreateSeuratObject(counts = pbmc.data, ##Unnormalized data such as raw counts or TPM\n",
        "    project = \"pbmc3k\", #Sets the project name for the Seurat object\n",
        "    min.cells = 3, #Include features detected in at least this many cells\n",
        "     min.features = 200) ##Include cells where at least this many features\n",
        "\n",
        "dim(pbmc)\n",
        "\n",
        "## An object of class Seurat"
      ],
      "metadata": {
        "id": "KtrUOOSrwu29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get more information"
      ],
      "metadata": {
        "id": "DaT8gOghwvVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See the QC **metrics**\n",
        "head(pbmc)"
      ],
      "metadata": {
        "id": "DiU13t5ptd98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets examine a few genes in the first thirty cells\n",
        "\n",
        "The \".\" values in the matrix represent 0s (no molecules detected). Since most values in an scRNA-seq matrix are 0, Seurat uses a sparse-matrix representation whenever possible. This results in significant memory and speed savings for Drop-seq/inDrop/10x data."
      ],
      "metadata": {
        "id": "0BubYK34uEuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets examine a few genes in the first thirty cells\n",
        "pbmc.data[c(\"Sox17\", \"Rp1\"), 1:30]\n",
        "\n",
        "#pbmc.data stored as sparse matrix\n",
        "sparse.size <- object.size(pbmc.data)\n",
        "sparse.size"
      ],
      "metadata": {
        "id": "I8jC-5eGuK0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QC and selecting cells for further analysis\n",
        "\n",
        "Seurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria. A few QC metrics commonly used by the community include\n",
        "\n",
        "* The number of unique genes detected in each cell\n",
        "    * Low-quality cells or empty droplets will often have very few genes\n",
        "    * Cell doublets or multiplets may exhibit an aberrantly high gene count\n",
        "* Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes)\n",
        "* The percentage of reads that map to the mitochondrial genome\n",
        "    * Low-quality / dying cells often exhibit extensive mitochondrial contamination\n",
        "    * We calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features\n",
        "    * We use the set of all genes starting with MT- as a set of mitochondrial genes\n"
      ],
      "metadata": {
        "id": "MGU88iAPucTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\n",
        "mito.genes <- grep(pattern = \"^mt\",\n",
        "                   x = rownames(x = pbmc@meta.data),\n",
        "                   ignore.case = TRUE, value = TRUE)\n",
        "\n",
        "# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\n",
        "pbmc[[\"percent.mt\"]] <- PercentageFeatureSet(pbmc, pattern = \"^mt-\")\n",
        "\n",
        "head(pbmc[[\"percent.mt\"]])"
      ],
      "metadata": {
        "id": "kBeuwXM6wt9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show QC metrics for the first 5 cells"
      ],
      "metadata": {
        "id": "TmEPDc-KucMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show QC metrics for the first 5 cells\n",
        "head(pbmc@meta.data, 5)"
      ],
      "metadata": {
        "id": "Oin6_BQnw0GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize QC metrics\n",
        "\n",
        "As a violin plot"
      ],
      "metadata": {
        "id": "dR_mnmHSucBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize QC metrics as a violin plot\n",
        "VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"),\n",
        "        ncol = 3)"
      ],
      "metadata": {
        "id": "LFBp5paNw35M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FeatureScatter is typically used to visualize feature-feature relationships, but can be used\n",
        "for anything calculated by the object, i.e. columns in object metadata, PC scores etc.\n"
      ],
      "metadata": {
        "id": "FtOW1mCUubwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot1 <- FeatureScatter(pbmc,\n",
        "                        feature1 = \"nCount_RNA\",\n",
        "                        feature2 = \"percent.mt\")\n",
        "plot2 <- FeatureScatter(pbmc,\n",
        "                        feature1 = \"nCount_RNA\",\n",
        "                        feature2 = \"nFeature_RNA\")\n",
        "plot1 + plot2"
      ],
      "metadata": {
        "id": "yH8ObJ5kxXkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering\n",
        "\n",
        "* We filter cells that have unique feature counts over 2,500 or less than 200\n",
        "* We filter cells that have >5% mitochondrial counts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R8WX8_qEubg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc2 <- subset(pbmc,\n",
        "  subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)\n",
        "dim(pbmc2)\n",
        "#number of samples went from"
      ],
      "metadata": {
        "id": "PY-ca5Ruxxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing the data\n",
        "\n",
        "After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[[\"RNA\"]]@data."
      ],
      "metadata": {
        "id": "jWRcbXo5x91y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc3 <- NormalizeData(pbmc2,\n",
        "                      normalization.method = \"LogNormalize\",\n",
        "                      scale.factor = 10000)\n",
        "\n",
        "#same step for normlization as above\n",
        "#pbmc <- NormalizeData(pbmc)\n",
        "\n",
        "dim(pbmc3)\n",
        "#14393   834"
      ],
      "metadata": {
        "id": "ms6N-TnvyAW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identification of highly variable features (feature selection)\n",
        "We next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\n",
        "\n",
        "The procedure in Seurat is described in detail here, and improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() function. By default, we return 2,000 features per dataset. These will be used in downstream analysis, like PCA."
      ],
      "metadata": {
        "id": "3eKsKaQYyJ4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc4 <- FindVariableFeatures(pbmc3,\n",
        "                             selection.method = \"vst\",\n",
        "                             nfeatures = 2000)\n",
        "\n",
        "dim(pbmc4) #13714  2638"
      ],
      "metadata": {
        "id": "rk9ez2XYyFkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the 10 most highly variable genes\n",
        "top10 <- head(VariableFeatures(pbmc4), 10)\n",
        "\n",
        "head(top10)"
      ],
      "metadata": {
        "id": "U4ocTBoQyWIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling the data\n",
        "Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function:\n",
        "\n",
        "* Shifts the expression of each gene, so that the mean expression across cells is 0\n",
        "* Scales the expression of each gene, so that the variance across cells is 1\n",
        "This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate\n",
        "* The results of this are stored in pbmc[[\"RNA\"]]@scale.data"
      ],
      "metadata": {
        "id": "A2aBaX3dygsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all.genes <- rownames(pbmc4)\n",
        "pbmc5 <- ScaleData(pbmc4, features = all.genes)"
      ],
      "metadata": {
        "id": "1kYJdmBr1vMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling is an essential step in the Seurat workflow, but only on genes that will be used as input to PCA. Therefore, the default in ScaleData() is only to perform scaling on the previously identified variable features (2,000 by default). To do this, omit the features argument in the previous function call, i.e.\n",
        "`pbmc <- ScaleData(pbmc) #only 2000 genes`.\n",
        "\n",
        "Your PCA and clustering results will be unaffected. However, Seurat heatmaps (produced as shown below with DoHeatmap()) require genes in the heatmap to be scaled, to make sure highly-expressed genes don’t dominate the heatmap. To make sure we don’t leave any genes out of the heatmap later, we are scaling all genes in this tutorial."
      ],
      "metadata": {
        "id": "YRe-TcM-1tAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To ‘regress out’ heterogeneity associated with (for example) cell cycle stage, or mitochondrial contamination.\n",
        "For particularly for advanced users who would like to use this functionality, we strongly recommend the use of the new normalization workflow, SCTransform(). The method is described in the paper, with a separate vignette using Seurat v3 here. As with ScaleData(), the function SCTransform() also includes a vars.to.regress parameter. https://satijalab.org/seurat/articles/sctransform_vignette.html"
      ],
      "metadata": {
        "id": "qcQAgeTR1s8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove unwanted sources of variation,\n",
        "pbmc6 <- ScaleData(pbmc5, vars.to.regress = \"percent.mt\")"
      ],
      "metadata": {
        "id": "CMY7SZ2J1_qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform linear dimensional reduction\n",
        "Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset."
      ],
      "metadata": {
        "id": "K06FVIox1s3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc7 <- RunPCA(pbmc6, features = VariableFeatures(object = pbmc6))\n",
        "\n",
        "#Seurat provides several useful ways of visualizing both cells and features that define the PCA, including VizDimReduction(), DimPlot(), and DimHeatmap()\n",
        "# Examine and visualize PCA results a few different ways\n",
        "print(pbmc7[[\"pca\"]], dims = 1:5, nfeatures = 5)\n",
        "VizDimLoadings(pbmc7, dims = 1:2, reduction = \"pca\")\n",
        "\n",
        "DimPlot(pbmc7, reduction = \"pca\")"
      ],
      "metadata": {
        "id": "Iko2WQWa2M6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number plots the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.\n"
      ],
      "metadata": {
        "id": "qzYpzCjX1sy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DimHeatmap(pbmc7, dims = 1:15, cells = 500, balanced = TRUE)"
      ],
      "metadata": {
        "id": "ecMdF46D2Sid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine the ‘dimensionality’ of the dataset\n",
        "To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many components should we choose to include? 10? 20? 100?\n",
        "\n",
        "In Macosko et al, we implemented a resampling test inspired by the JackStraw procedure. We randomly permute a subset of the data (1% by default) and rerun PCA, constructing a ‘null distribution’ of feature scores, and repeat this procedure. We identify ‘significant’ PCs as those who have a strong enrichment of low p-value features.\n",
        "\n",
        "NOTE: This process can take a long time for big datasets, comment out for expediency. More approximate techniques such as those implemented in ElbowPlot() can be used to reduce computation time\n",
        "\n",
        "```\n",
        "#pbmc8 <- JackStraw(pbmc7, num.replicate = 100)\n",
        "#pbmc8 <- ScoreJackStraw(pbmc8, dims = 1:20)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Dz8I7YoM1ss5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Elow plot\n",
        "An alternative heuristic method generates an ‘Elbow plot’: a ranking of principle components based on the percentage of variance explained by each one (ElbowPlot() function). In this example, we can observe an ‘elbow’ around PC9-10, suggesting that the majority of true signal is captured in the first 12 PCs.\n",
        "\n"
      ],
      "metadata": {
        "id": "EI0hqIzF2geQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow plot\n",
        "ElbowPlot(pbmc7)"
      ],
      "metadata": {
        "id": "i6BvLIAE2aDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying the true dimensionality of a dataset – can be challenging/uncertain for the user. We therefore suggest these three approaches to consider.\n",
        "* The first is more supervised, exploring PCs to determine relevant sources of heterogeneity, and could be used in conjunction with GSEA for example.\n",
        "* The second implements a statistical test based on a random null model, but is time-consuming for large datasets, and may not return a clear PC cutoff.\n",
        "* The third is a heuristic that is commonly used, and can be calculated instantly.\n",
        "\n",
        "In this example, all three approaches yielded similar results, but we might have been justified in choosing anything between PC 7-12 as a cutoff. We chose 10 PCs here\n",
        "\n",
        "The Seurat authors advise users to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results."
      ],
      "metadata": {
        "id": "PXn70_B72k_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cluster the cells\n",
        "Seurat v3 applies a graph-based clustering approach, building upon initial strategies\n",
        "in (Macosko et al). Importantly, the distance metric which drives the clustering analysis\n",
        "(based on previously identified PCs) remains the same. However, our approach to partitioning\n",
        "the cellular distance matrix into clusters has dramatically improved. The approach was heavily\n",
        "inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data\n",
        "Briefly, these methods embed cells in a graph structure - for example a **K-nearest neighbor\n",
        "(KNN) graph**, with edges drawn between cells with similar feature expression patterns, and\n",
        "then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or\n",
        "‘communities’.\n",
        "\n",
        "* As in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods **(Jaccard similarity)**. This step is performed using the `FindNeighbors()` function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).\n",
        "* To cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The `FindClusters()` function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. Setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the `Idents()` function.\n"
      ],
      "metadata": {
        "id": "nHibjkiB24A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfDims = 12\n",
        "\n",
        "pbmc8 <- FindNeighbors(pbmc7, dims = 1:numberOfDims)\n",
        "pbmc8 <- FindClusters(pbmc8, resolution = 0.5)\n",
        "#Number of nodes: 2638\n",
        "#Number of edges: 95905\n",
        "\n",
        "# Look at cluster IDs of the first 5 cells\n",
        "head(Idents(pbmc8), 5)"
      ],
      "metadata": {
        "id": "hY2UE2LC2oZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run non-linear dimensional reduction (UMAP/tSNE)\n",
        "Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.\n"
      ],
      "metadata": {
        "id": "WkvTQnyA2_Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you haven't installed UMAP, you can do so via reticulate::py_install(packages =\n",
        "#'umap-learn')\n",
        "pbmc9 <- RunUMAP(pbmc8, dims = 1:numberOfDims)\n",
        "\n",
        "# note that you can set `label = TRUE` or use the LabelClusters function to help label\n",
        "#individual clusters\n",
        "DimPlot(pbmc9, reduction = \"umap\")\n",
        "\n",
        "#You can save the object at this point so that it can easily be loaded back in without\n",
        "#having to rerun the computationally intensive steps performed above, or easily shared with collaborators.\n",
        "\n",
        "saveRDS(pbmc9, file = \"/content/sample_data/Seurat_tutorial2.rds\")"
      ],
      "metadata": {
        "id": "APjpLJRO3TGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding differentially expressed features (cluster biomarkers)\n",
        "Seurat can help find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.\n",
        "\n",
        "The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significant and the most highly differentially expressed features will likely still rise to the top."
      ],
      "metadata": {
        "id": "MIfJtPiU2_NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find markers for every cluster compared to all remaining cells, report only the positive ones\n"
      ],
      "metadata": {
        "id": "3pkjy6zt3x4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc.markers <- FindAllMarkers(pbmc9,\n",
        "                               only.pos = TRUE,\n",
        "                               min.pct = 0.25,\n",
        "                               logfc.threshold = 0.25)\n",
        "\n",
        "de.markers <- pbmc.markers %>%\n",
        "    group_by(cluster) %>%\n",
        "    slice_max(n = 2, order_by = avg_log2FC)\n",
        "\n",
        "head(de.markers)\n",
        "write.csv(de.markers, file = \"/content/sample_data/Tutorial2_demarkers.csv\")\n"
      ],
      "metadata": {
        "id": "ww2kaZl83zck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seurat has several tests for differential expression which can be set with the test.use parameter (see our DE vignette for details). For example, the ROC test returns the ‘classification power’ for any individual marker (ranging from 0 - random, to 1 - perfect)."
      ],
      "metadata": {
        "id": "xSNHTqdn32s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster0.markers <- FindMarkers(pbmc9,\n",
        "                                ident.1 = 0,\n",
        "                                logfc.threshold = 0.25,\n",
        "                                test.use = \"roc\",\n",
        "                                only.pos = TRUE)\n",
        "head(cluster0.markers)\n",
        "write.csv(de.markers, file = \"/content/sample_data/Tutorial2_classif.power.csv\")"
      ],
      "metadata": {
        "id": "4F_3Cz3A34t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visulize markers\n",
        "There are several tools for visualizing marker expression.\n",
        "* VlnPlot() (shows expression probability distributions across clusters), and * FeaturePlot() (visualizes feature expression on a tSNE or PCA plot) are the most commonly used visualizations.\n",
        "* RidgePlot(), CellScatter(), and DotPlot()"
      ],
      "metadata": {
        "id": "8dmgtfT936iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DoHeatmap() generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.\n"
      ],
      "metadata": {
        "id": "CCBEEceZ5Wtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbmc.markers %>%\n",
        "    group_by(cluster) %>%\n",
        "    top_n(n = 10, wt = avg_log2FC) -> top10\n",
        "\n",
        "DoHeatmap(pbmc9, features = top10$gene) + NoLegend()"
      ],
      "metadata": {
        "id": "J-V14NR_5YOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write session info\n",
        "sessionInfo()\n"
      ],
      "metadata": {
        "id": "A5GMB7UK5moE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial complete\n",
        "The tutorial is now complete. Please download the two RDS files exported to the output directory '/content/sample_data/', and the images generated as they will not be stored permanently\n",
        "\n"
      ],
      "metadata": {
        "id": "-3Bj5ktS5os0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "* https://satijalab.org/seurat/articles/pbmc3k_tutorial.html\n",
        "* https://learn.gencore.bio.nyu.edu/single-cell-rnaseq/loading-your-own-data-in-seurat-reanalyze-a-different-dataset/"
      ],
      "metadata": {
        "id": "82lFuPOZUhEj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}